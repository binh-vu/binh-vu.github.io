---
layout: post
title:  "From Sketches to HTML/CSS code"
date:   2019-04-27 13:08:19 -0700
categories: projects csci-599
---

<img style="display: block; margin-left: auto; margin-right: auto" src="/assets/20190427-sketch2code/demo.gif" />

# Introduction

Creating websites is a difficult task that requires expertise and a significant amount of time. In a typical web development workflow, web developers implement HTML/CSS and Javascript code based on a mock-up UI, which are created using applications such as Sketch. A task of synthesising HTML/CSS programs from mock-up UIs helps speed up the development process by allowing developers to focus more on implementing Javascript logic.

In this post, we present a system that directly generates HTML/CSS programs from the screenshot image of mock-up UIs. In particular, given a HTML/CSS libraries containing a set of HTML tags $$\mathcal{T}$$ and CSS classes $$\mathcal{C}$$, the system converts a screenshot $$I$$ of a target mock-up UI into HTML/CSS program $$P$$ that renders $$I$$.
We have consider two approaches: supervised approach and reinforcement learning approach. However, due to time constraint.

# Generating HTML/CSS Code with Neural-Guided Search

Similar to XML, a HTML program consists of a sequence of HTML tags, each tag can be an open tag or an close tag (e.g., `<h5>` and `</h5>`). In addition, open tags may contain other special attributes such as `class` to indicate classes they belong to (e.g., `<div class="row">`). In our system, we represent a HTML program as a sequence of tokens, each token is either an open tag, an close tag, an open tag and its classes, or one of three special tokens: `#text`, `<program>`, `</program>`.

Let $$f$$ is a function that predict probabilities of the next tokens $$x_{t+1}$$ of the program given a current sequence of tokens $X_t$ and a target image $$I$$. Then, the desired program $$P$$ can be generated by repeated applying $$f$$ to generate one token by one token, and invoke the rendering program to evaluate the current program until we find the `</program>` token that indicates the end of the program.

To estimate $$f$$, we train a deep learning model that uses CNN to encode a target image to a representation vector $$z$$, then feeds $$z$$ with current tokens $$X_t$$ of the program to an LSTM to decode the next token $$x_{t+1}$$. We have tried three variants of combination $$z$$ and $$X_t$$ as below:

1. Use $$z$$ as hidden state
2. Concatenate $$z$$ with each $$x_{t' < t} \in X_t$$
3. Attention model

# Related Work

Pix2code

# Empirical Evaluating

We are evaluting 

# Discussion and Future work

# References

# Appendix

#### Reinforcement Learning Approach

<style>
	.post-content {
		text-align: justify;
	}
</style>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>

