<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>From Sketches to HTML/CSS code | Binh Vu</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="From Sketches to HTML/CSS code" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Given the mock-up UI on the left, our system synthesizes HTML/CSS code (middle) that renders the website on the right Introduction" />
<meta property="og:description" content="Given the mock-up UI on the left, our system synthesizes HTML/CSS code (middle) that renders the website on the right Introduction" />
<link rel="canonical" href="http://localhost:4000/projects/csci-599/2019/04/27/from-sketches-to-html-css-code.html" />
<meta property="og:url" content="http://localhost:4000/projects/csci-599/2019/04/27/from-sketches-to-html-css-code.html" />
<meta property="og:site_name" content="Binh Vu" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-27T13:08:19-07:00" />
<script type="application/ld+json">
{"headline":"From Sketches to HTML/CSS code","url":"http://localhost:4000/projects/csci-599/2019/04/27/from-sketches-to-html-css-code.html","datePublished":"2019-04-27T13:08:19-07:00","dateModified":"2019-04-27T13:08:19-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/projects/csci-599/2019/04/27/from-sketches-to-html-css-code.html"},"description":"Given the mock-up UI on the left, our system synthesizes HTML/CSS code (middle) that renders the website on the right Introduction","@type":"BlogPosting","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Binh Vu" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Binh Vu</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">From Sketches to HTML/CSS code</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-04-27T13:08:19-07:00" itemprop="datePublished">Apr 27, 2019
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <figure>
	<img src="/assets/20190427-sketch2code/demo.gif" />
	<figcaption>Given the mock-up UI on the left, our system synthesizes HTML/CSS code (middle) that renders the website on the right</figcaption>
</figure>
<h1 id="introduction">Introduction</h1>

<p>Creating websites is a difficult task that requires expertise and a significant amount of time. In a typical web development workflow, web developers implement HTML/CSS and Javascript code based on a mock-up UI, which are created using applications such as Sketch. A task of synthesising HTML/CSS programs from mock-up UIs helps speed up the development process by allowing developers to focus more on implementing Javascript logic.</p>

<p>In this post, we discuss our approaches to address the above problem, which is formally described as follow. Given a set of HTML tags <script type="math/tex">\mathcal{T}</script>, classes <script type="math/tex">\mathcal{C}</script> of CSS libraries, and a screenshot <script type="math/tex">I</script> of a target mock-up UI, we generate a HTML program <script type="math/tex">P</script> that renders <script type="math/tex">I</script>.</p>

<p>We experiment with two different approaches: supervised and reinforcement learning (RL). In the reinforcement learning approach, we aim to learn a Deep Q-network to synthesis HTML program without labelled data. Because the problem space in RL is enormous and we have limited resources, we have not successfully made RL to work. The details of our RL approach is described in the Appendix. In the supervised approach, we use CNN to encode the target image <script type="math/tex">I</script> and LSTM to decode the HTML program <script type="math/tex">P</script> from <script type="math/tex">I</script>. In our empirical evaluation, it outperforms the current state-of-the-art (pix2code) significantly by 19.7% (accuracy).</p>

<p>The most relevant work to this problem is pix2code, which also synthesizes HTML programs from images. Besides the different between neural network architecture, their approach first generates domain specific language (DSL) programs. Then, translate DSL programs to final HTML programs. Using DSL makes this problem easier. However, creating DSL may take lots of time and we may need to create different DSL or different DSL-to-HTML converter for different CSS libraries. By directly generating HTML/CSS program, our approach is easier to adapt to different CSS libraries, and is able to access to a tremendous amount of publicly available training data in open source projects and websites.</p>

<p>In the remained post, we will described different supervised models and their performances comparing to the current state-of-the-art</p>

<h1 id="generating-htmlcss-code-with-neural-guided-search">Generating HTML/CSS Code with Neural-Guided Search</h1>

<p>Similar to XML, a HTML program consists of a sequence of HTML tags, each tag can be an open tag or an close tag (e.g., <code class="highlighter-rouge">&lt;h5&gt;</code> and <code class="highlighter-rouge">&lt;/h5&gt;</code>). In addition, open tags may contain other special attributes such as <code class="highlighter-rouge">class</code> to indicate classes they belong to (e.g., <code class="highlighter-rouge">&lt;div class="row"&gt;</code>). In our system, we represent a HTML program as a sequence of tokens, each token is either an open tag, an close tag, an open tag and its classes, or one of three special tokens: <code class="highlighter-rouge">#text</code>, <code class="highlighter-rouge">&lt;program&gt;</code>, <code class="highlighter-rouge">&lt;/program&gt;</code>. The <code class="highlighter-rouge">#text</code> token acts as a placeholder for text elements in the mock-up UI. <code class="highlighter-rouge">&lt;program&gt;</code> and <code class="highlighter-rouge">&lt;/program&gt;</code> indicate the begining and ending of the HTML program, repsectively.</p>

<p>Let <script type="math/tex">f</script> is a function that predict probabilities of the next tokens <script type="math/tex">x_{t+1}</script> of the program given a current sequence of tokens <script type="math/tex">X_t</script> and a target image <script type="math/tex">I</script>. Then, the desired program <script type="math/tex">P</script> can be generated by repeated applying <script type="math/tex">f</script> to generate one token by one token, and optionally invoke the rendering program to evaluate the current program until we find the <code class="highlighter-rouge">&lt;/program&gt;</code> token.</p>

<p>To estimate <script type="math/tex">f</script>, we train a deep learning model that uses CNN to learn a representation vector <script type="math/tex">z</script> of a target image, then inputs <script type="math/tex">z</script> with current tokens <script type="math/tex">X_t</script> of the program to an LSTM to predict the next token <script type="math/tex">x_{t+1}</script>. We experiment with three different architectures, each have different ways of usages of <script type="math/tex">z</script> and <script type="math/tex">X_t</script>, as follow:</p>

<ul>
  <li><strong>Using <script type="math/tex">z</script> as the initial hidden state of LSTM</strong>: the architecture of this model (ED-1) is showed in the figure below. It contains of three CNN layers extracting features from a image, then passes to a fully connected layer to extract a representation vector <script type="math/tex">z</script> of size 512. <script type="math/tex">z</script> is used as the hidden state of a one-layer LSTM (hidden states are vectors of <script type="math/tex">R^{512}</script>). LSTM is trained to predict next tokens of target HTML programs.</li>
</ul>

<figure>
	<img src="/assets/20190427-sketch2code/model-ed-1.png" />
	<figcaption>Network architecture of model ED-1</figcaption>
</figure>

<ul>
  <li><strong>Concatenating <script type="math/tex">z</script> with each <script type="math/tex">x_{t' \le t} \in X_t</script></strong>: the architecture of this model (ED-2) is similar to the above model (figure below). However, instead of using <script type="math/tex">z</script> as initial hidden state, <script type="math/tex">z</script> is concatenate with vectors of tokens <script type="math/tex">X_t</script> and is inputed to the LSTM.</li>
</ul>

<figure>
	<img src="/assets/20190427-sketch2code/model-ed-2.png" />
	<figcaption>Network architecture of model ED-2</figcaption>
</figure>

<ul>
  <li><strong><script type="math/tex">z</script> is computed dynamically at each time step <script type="math/tex">t</script> using an attention layer, and is concatenated with the input token <script type="math/tex">x_{t'}</script> to predict next token <script type="math/tex">x_{t'+1}</script></strong></li>
</ul>

<figure>
	<img src="/assets/20190427-sketch2code/model-ed-3.png" />
	<figcaption>Network architecture of model ED-3</figcaption>
</figure>

<h1 id="experimental-evaluation">Experimental Evaluation</h1>

<p><strong>Dataset and experimental setup</strong></p>

<p>We evaluate our approach on the synthesized web dataset from pix2code [1]. The dataset contains 1750 images of web pages, in which 1250, 250, and 250 pages are used for training, validation and testing, respectively. We assess the quality of predicted programs by comparing with gold programs in term of accuracies as in pix2code [1].</p>

<script type="math/tex; mode=display">\text{accuracy(gp, pp)} = \frac{\sum_{i=0}^{min(|\text{gp}|, |\text{pp}|)} \text{gp}[i] = \text{pp}[i]}{max(|\text{gp}|, |\text{pp}|)}</script>

<p>where <script type="math/tex">\text{gp}</script> and <script type="math/tex">\text{pp}</script> are the predicted program and gold program, respectively, and <script type="math/tex">\text{gp}[i]</script> is a token at position <script type="math/tex">i</script> of the program.</p>

<p><strong>Training supervised models</strong></p>

<p>The three models (ED-1, ED-2, ED-3) are trained using ADAM-AMSGRAD optimization method for 100 epoches with learning rate 5e-4. The training task is to minimize the cross entropy loss of predicting next tokens of a program given the current tokens and a target image. We report the average loss and the average classification accuracy for predicted tokens in figures below.</p>

<figure>
	<img style="width: 90%" src="/assets/20190427-sketch2code/training-stats.png" />
	<figcaption>Training losses and classification accuracy per epoch</figcaption>
</figure>

<figure>
	<img style="width: 90%" src="/assets/20190427-sketch2code/validation-stats.png" />
	<figcaption>Validation losses and classification accuracy per epoch</figcaption>
</figure>

<figure>
	<img style="width: 90%" src="/assets/20190427-sketch2code/testing-stats.png" />
	<figcaption>Testing losses and classification accuracy per epoch</figcaption>
</figure>

<p><strong>Automatic synthesizing HTML programs results</strong></p>

<table>
  <thead>
    <tr>
      <th>Datasets</th>
      <th style="text-align: center">pix2code*</th>
      <th style="text-align: center">ED-1</th>
      <th style="text-align: center">ED-2</th>
      <th style="text-align: center">ED-3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>pix2code</td>
      <td style="text-align: center">0.794</td>
      <td style="text-align: center">0.722</td>
      <td style="text-align: center">0.982</td>
      <td style="text-align: center"><strong>0.991</strong></td>
    </tr>
  </tbody>
</table>

<figure>
	<img style="width: 90%" src="/assets/20190427-sketch2code/attention.png" />
	<figcaption>Testing losses and classification accuracy per epoch</figcaption>
</figure>

<figure>
	<img style="width: 70%" src="/assets/20190427-sketch2code/layer1-activation.png" />
	<figcaption>Testing losses and classification accuracy per epoch</figcaption>
</figure>

<h1 id="references">References</h1>

<ol>
  <li>Beltramelli, Tony. “Pix2code: Generating Code from a Graphical User Interface Screenshot.” Proceedings of the ACM SIGCHI Symposium on Engineering Interactive Computing Systems, 2018, p. 3.</li>
</ol>

<h1 id="appendix">Appendix</h1>

<h4 id="reinforcement-learning-approach">Reinforcement Learning Approach</h4>

<p><strong>Problem formulation</strong></p>

<p>The problem of generating HTML program can be formulate to RL as follows: the state is a pair of a target GUI image and our current program. Possible actions are creating a new HTML tag, adding new CSS class to the current tag, and closing a HTML tag. The reward of a state is calculated by how similar it is between its desired GUI image, and the current webpage, which rendered from its current program.</p>

<p><strong>Reward and training</strong></p>

<figure>
	<img style="width: 70%" src="/assets/20190427-sketch2code/reward.png" />
	<figcaption>Testing losses and classification accuracy per epoch</figcaption>
</figure>

<p><strong>Preliminary results</strong></p>

<figure>
	<img src="/assets/20190427-sketch2code/reinforcement-learning-stats.png" />
	<figcaption>Testing losses and classification accuracy per epoch</figcaption>
</figure>

<style>
	.post-content {
		text-align: justify;
	}
	/* make math/tex inline for figure caption */
	figcaption > span {
		display: inline-block !important;
		margin: 0 !important;
	}
	figure > img {
		display: block; 
		margin-left: auto; 
		margin-right: auto;
	}
	figcaption {
		text-align: center;
		font-style: italic;
		width: 80%;
		margin-left: auto;
		margin-right: auto;
	}
</style>

<script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


  </div><a class="u-url" href="/projects/csci-599/2019/04/27/from-sketches-to-html-css-code.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Binh Vu</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Binh Vu</li><li><a class="u-email" href="mailto:binhlvu@gmail.com">binhlvu@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/binh-vu"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">binh-vu</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p></p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
